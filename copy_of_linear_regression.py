# -*- coding: utf-8 -*-
"""Copy of Linear-Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MBAyMdcxkcJ5-yE8GFniGI348VsTWHjt

# Linear Regression
"""

from google.colab import drive
drive.mount('/content/drive')

"""
We begin with the standard imports:"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
import numpy as np

"""## Simple Linear Regression

We will start with the most familiar linear regression, a straight-line fit to data.
A straight-line fit is a model of the form
$$
y = a + b(x)
$$
where $b$ is commonly known as the *slope*, and $a$ is commonly known as the *intercept*.

Consider the following data
"""

x = np.array([16, 17, 19, 20, 22, 23.5, 24])
y = np.array([685, 640, 670, 660, 630, 660, 635])
plt.scatter(x, y);

"""We can use Scikit-Learn's ``LinearRegression`` estimator to fit this data and construct the best-fit line:"""

from sklearn.linear_model import LinearRegression
model = LinearRegression(fit_intercept=True)

model.fit(x[:, np.newaxis], y)

xfit = np.linspace(0, 30, 1000)
yfit = model.predict(xfit[:, np.newaxis])

plt.scatter(x, y)
plt.plot(xfit, yfit);

"""The slope and intercept of the data are contained in the model's fit parameters, which in Scikit-Learn are always marked by a trailing underscore.
Here the relevant parameters are ``coef_`` and ``intercept_``:
"""

print("Model slope:    ", model.coef_[0])
print("Model intercept:", model.intercept_)